{
"version":3,
"file":"module$bfuncs$termsParser.js",
"lineCount":3,
"mappings":"AAAAA,cAAA,CAAe,yBAAf,CAA8C,QAAQ,CAACC,MAAD,CAAQC,OAAR,CAAgBC,MAAhB,CAAuBC,OAAvB,CAAgC,CAEtF,CAAM,CAAC,OAAAC,MAAD,CAAN,CAAiBH,OAAA,CAAQ,0CAAR,CAAjB,CACA,EAAM,CAAC,SAAAI,MAAD,CAAN,CAAmBJ,OAAA,CAAQ,0CAAR,CAAnB,CACA,OAAM,CAACK,IAAD,CAAA,CAASL,OAAA,CAAQ,sBAAR,CACfE,QAAA,CAAQI,MAAR,CAAiBH,MAAA,CAAOI,WAAP,CAAmB,CAClCC,QAAS,EADyB,CAElCC,OAAQ,+EAF0B,CAGlCC,UAAW,iEAHuB,CAIlCC,KAAM,iCAJ4B;AAKlCC,UAAW,sCALuB,CAMlCC,QAAS,EANyB,CAOlCC,UAAW,CACT,CAACV,MAAD,CAAUW,KAAV,CAAiB,EAAjB,CAAoB,CAApB,CAAsB,CAAtB,CAAwB,CAAxB,CAA0B,CAA1B,CAA4B,MAA5B,CADS,CAPuB,CAUlCC,aAAc,CAAC,CAAD,CAVoB,CAWlCC,gBAAiB,CAXiB,CAYlCC,UAAW,uWAZuB;AAalCC,WAAY,CAAC,CAAD,CAbsB,CAclCC,SAAU,CAAC,UAAY,CAAC,CAAD,CAAG,CAAH,CAAb,CAdwB,CAelCC,YAAa,CAAC,CAAChB,KAAM,EAAP,CAAWiB,IAAK,CAACC,KAAD,CAAQC,KAAR,CAAAF,EAAmBjB,IAAA,CAAKkB,KAAL,CAAYC,KAAZ,CAAnBF,EAAyC,CAAzCA,CAA8C,CAA9D,CAAD,CAfqB,CAgBlCG,UAAW,CAhBuB,CAAnB,CALqE;",
"sources":["bfuncs/termsParser.js"],
"sourcesContent":["shadow$provide[\"module$bfuncs$termsParser\"] = function(global,require,module,exports) {\n// This file was generated by lezer-generator. You probably shouldn't edit it.\nconst {Parser} = require(\"lezer\")\nconst {NodeProp} = require(\"lezer\")\nconst {term} = require(\"./tokens\")\nexports.parser = Parser.deserialize({\n  version: 13,\n  states: \"!QOVQPOOOOQO'#Ch'#ChQhQPOOOOQO'#Cd'#CdQ|QPO'#CdQhQPOOOOQO,59O,59OOOQO-E6b-E6b\",\n  stateData: \"!_~OZOS~OPPOQPORPOSPOTQO~OPPOQPORPOSPOTROVSO~OPPOQPORPOSPOTUO~O\",\n  goto: \"n]PPPPPPPP^PPPdQTQRVTQQOSRQTRUS\",\n  nodeNames: \"\u26a0 Dec Bin Oct Hex None TermsList Sep\",\n  maxTerm: 13,\n  nodeProps: [\n    [NodeProp.group, -4,1,2,3,4,\"term\"]\n  ],\n  skippedNodes: [0],\n  repeatNodeCount: 1,\n  tokenData: \"$h~RiOX!pX^#n^p!ppq#nq|!p|}$c}!]!p!]!^$c!^#y!p#y#z#n#z$f!p$f$g#n$g#BY!p#BY#BZ#n#BZ$IS!p$IS$I_#n$I_$I|!p$I|$JO#n$JO$JT!p$JT$JU#n$JU$KV!p$KV$KW#n$KW&FU!p&FU&FV#n&FV~!p~!u]]~OX!p^p!pq|!p}!]!p!^#y!p#z$f!p$g#BY!p#BZ$IS!p$I_$I|!p$JO$JT!p$JU$KV!p$KW&FU!p&FV~!p~#sYZ~X^#npq#n#y#z#n$f$g#n#BY#BZ#n$IS$I_#n$I|$JO#n$JT$JU#n$KV$KW#n&FU&FV#n~$hOV~\",\n  tokenizers: [0],\n  topRules: {\"TermsList\":[0,6]},\n  specialized: [{term: 13, get: (value, stack) => (term(value, stack) << 1) | 1}],\n  tokenPrec: 0\n})\n\n};"],
"names":["shadow$provide","global","require","module","exports","Parser","NodeProp","term","parser","deserialize","version","states","stateData","goto","nodeNames","maxTerm","nodeProps","group","skippedNodes","repeatNodeCount","tokenData","tokenizers","topRules","specialized","get","value","stack","tokenPrec"]
}
